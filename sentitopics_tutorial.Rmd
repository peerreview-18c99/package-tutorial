---
title: "D Using the sentitopics R-package"
output:
  pdf_document: 
    toc: false
    toc_depth: 2
    keep_tex: yes
  html_document: 
    css: style.css
    code_folding: show
    highlight: tango
    theme: united
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(scipen = 999)
```

# Introduction

In this tutorial we show how interested reasearchers can easily get started with JST and rJST models using the [sentitopics](https://github.com/cpipal/senttitopics) R package. We demonstrate an example workfrom from start (reading in a text corpus) to finish (visualizing JST and rJST results). 

The repository can be found at: [https://github.com/cpipal/sentitopics-tutorial](https://github.com/cpipal/sentitopics-tutorial). There you can always find the up-to-date version. 

```{r, include = FALSE}
# load packages
if (!require(tidyverse)) {
  install.packages('tidyverse')
}
if (!require(quanteda)) {
  install.packages('quanteda')
}
if (!require(tidytext)) {
  install.packages('tidytext')
}
if (!require(foreach)) {
  install.packages('foreach')
}
if (!require(rngtools)) {
  install.packages('rngtools')
}
if (!require(tictoc)) {
  install.packages('tictoc')
}
if (!require(ggraph)) {
  install.packages('ggraph')
}
if (!require(devtools)) {
  install.packages('devtools')
}
if (!require(sentitopics)) {
  devtools::install_github("cpipal/sentitopics")
}
library(sentitopics)
if (!require(tm)) {
  install.packages('tm')
}
```


# Installing the package

We can install the sentitopics package from Github using the `install_github()` function from the `devtools` package. You might have to activate the C++11 mode of the C++ compiler first:

```{r, eval = FALSE}
Sys.setenv("PKG_CXXFLAGS"="-std=c++11") # activate C++11 compiler

library(devtools)
install_github('cpipal/sentitopics')

```


# Preparing the data

We use two data sources:

* `EUSpeech v2` = Dataset of EU leader speeches [Schumacher et al. (2020)](https://osf.io/c79ha/)
* `LSD2015` = Lexicoder sentiment dictionary as provided by quanteda

Load the EUSpeech v2 corpus and select speeches from the United Kingdom:
```{r, cache = TRUE}
load("data/EUspeech_V2.RData") 
corpus <- corpus %>% 
  quanteda::corpus_subset(country == "Great Britain")

```


Then turn the texts into a `quanteda` dfm (document-feature matrix). We apply a couple of preprocessing steps such as stopword removal, lowercasing, and stemming.
```{r, cache = TRUE}
dfm <- corpus %>% 
    dfm(verbose = TRUE,
        tolower = TRUE,
        remove = stopwords("english"), 
        remove_punct = TRUE,
        remove_numbers = TRUE) %>% 
    dfm_wordstem(language = "english")

```

We also create a `dtm` object so we can show that the `sentitopics` package can also work with a document term matrix as input (this comes in handy if you prefer to use the `tidytext` or `tm` text analysis packages).

```{r}
dtm <- dfm %>% quanteda::convert(to = "tm")

```

Now the only thing left is that we have to load a dictionary that we want to use as the supervised input for the JST/rJST models. Here we are going to use the Lexcoder dictionary that comes with the `quanteda` package.

```{r}
dict <- quanteda::data_dictionary_LSD2015[1:2]

```





# Estimating speech-level sentiment with JST

We can estimate the speech-level sentiment using the `jst()` function of the `sentitopics` package. Similarl to LDA, we have to choose the number of topics and iterations. We can also experiment with hyperparameter settings, but going with the default values is usually fine.
```{r, cache = TRUE}
set.seed(1899)
jst_out <- sentitopics::jst(dfm, dict, numTopics = 30, numIters = 100)

```

That's it! We can now easily inspect the different model results using the `get_parameter()` function. Let's try this to get the speech-level sentiment estimates for each speech in our dataset:

```{r}
pi <- sentitopics::get_parameter(jst_out, "pi")
pi %>% 
  select(sent1, sent2, sent3) %>% 
  head()

```

What do thoese labels sent1, sent2, sent3 mean? JST is able to estimate 2 (positive, negative) or 3 (neutral, positive, negative) sentiment estimates. Because we opted for the default parameters when running the model, we estimated all three categories. Essentially, JST results are probabilities that a document belongs to one of the 2 (or in our case 3) sentiment categories. For instance, JST estimated that the probability of the first text (text5343) being neutral is 0.42 (sent1), the probability of it being positive is 0.25 (sent2), and the probability of the text being negative is 0.34 (sent3). We can also use these probabilities to calculate an overall sentiment score. For this we substract the negative score of a text from its positive score.

```{r}
pi %>% 
  mutate(sentiment = sent2 - sent3) %>% 
  select(sentiment) %>% 
  head()

```

We can also repeat this using the `dtm` object we just created instead of the `dfm`. The results are the same.
```{r, echo = TRUE, cache = TRUE}
set.seed(1899)
jst_out <- sentitopics::jst(dtm, dict, numTopics = 30, numIters = 100)
pi <- sentitopics::get_parameter(jst_out, "pi")
pi %>% 
  select(sent1, sent2, sent3) %>% 
  head()

```


## Running JST many times

Similar to LDA models, JST model results usually differ across model model runs to some degree. We can use this variation to compute uncertainty estimates around sentiment scores by running JST several times. To run the model several times, we can use the `jstManyRuns()` function. Here we just have to specify how often we want to run the model. It is important to note here that the function only returns the averaged results of the document-level sentiment scores and their associated uncertainty measures. Keeping all model information would quickly result into reaching RAM limits. In our example we run the model 10 times, and use the default settings for the number of CPU cores (available cores  - 3). We could change those settings by using the parameter ncores. 

```{r, echo = TRUE}
set.seed(1899)
res <- sentitopics::jstManyRuns(dfm, dict, numIters = 10, n = 10)

res %>% 
  select(sent2_mean, sent2_sd, sent2_se, sent2_ci_high, sent2_ci_low) %>% 
  head()




```


Let's use these last results to investigate how the sentiment of prime minister speeches in the UK developed over time:


```{r, cache = TRUE}
library(zoo)
data <- res %>% 
  mutate(sentiment = sent2_mean - sent3_mean) %>% 
  mutate(year_month = as.yearmon(date)) %>% 
  group_by(year_month) %>% 
  summarise(sentiment = mean(sentiment))


plot <- data %>% 
  ggplot(aes(x = year_month, y = sentiment)) +
  geom_point(shape = 1, color = "black", size=1) +
  geom_smooth(color = "black", se = TRUE, size = 1, level = 0.95) +
  ylab("Sentiment") +
  xlab("") + 
  scale_x_continuous(name = "",
                     breaks = c(2007:2020))

plot




```


# Estimating topic-specific sentiment with rJST

While JST assumes that a document is first structured by its sentiment, rJST assumend that a text is structured by topics first. We can therefore use the rJST model to estimate topic-specific sentiment (e.g. how positive/negative is a text about the EU). Estimating a rJST model with the `sentitopics` can also easily be done with the `jst_reversed()` function. Again, we have to specify the number of topics we expect to find in the corpus. In addition, we also can play around with the hyperparameter settings. In this example we just use the default settings and run the model 100 times (You should use more iterations in a real application).

```{r, cache = TRUE}
set.seed(1899)
rjst <- sentitopics::jst_reversed(dfm, dict, numTopics = 30, numIters = 1000, 
                                  alpha = 1, gamma = 50, updateParaStep = 50)
```

How do rJST senti-topics look like? First, we ce can extract the words that load highly on each topic-sentiment with the `top20words()` or `topNwords()` functions. These words list are similar to what you would get from an LDA mode, but with an important addition: For each topic we get three word lists: One each for neutral, positive, and negative topic-sentiment. 

We'll display the top words for the first three topics. Looks like these topics are about the economy/trade, security, and the European Union:



```{r, cache = TRUE}
words <- rjst %>% sentitopics::top20words()

head(words[,1:9])


```














